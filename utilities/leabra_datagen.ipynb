{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "605ac233",
   "metadata": {},
   "source": [
    "## Produce good and bad images for training and testing\n",
    "Using this notebook, you can quickly produce good and bad datasets. Basic interactive console to start building datasets. Producing a variety of results by changing clothing, camera angle, body position, lighting, etc. It is not recommended to choose a large batch size. Try it out with a small batch size and adjust the `frames_to_hold` variable up for faster hardware and down for slower hardware. This is both to avoid false pauses in motion due as well as to avoid fatigue from holding a squat for too long. By default, this notebook will speak \"ok\", everytime it captures. Setting `use_speech = False` will disable this feature. DISCLAIMER: Doing bad squats on purpose is bad for your health. We do not recommend doing any exercise incorrectly.\n",
    "<br><br>\n",
    "The program will ask you for input of 'g' or 'b' for good or bad, or 'q'  to quit the loop and complete the cells execution, saving the images.  You may use the same loop to do both good and bad until you are done and choose 'q', or provide keyboard_interrupt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "086821d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import clear_output, Image, display, HTML, Audio, Javascript as js\n",
    "import cv2\n",
    "import numpy as np\n",
    "from skimage import metrics\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b492031d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Disable speech notification below:\n",
    "use_speech = True\n",
    "def speak(display_handle,text):\n",
    "    \n",
    "    text = text.replace(\"'\",r\"\\'\")\n",
    "    display_handle.update(js('''\n",
    "    if(window.speechSynthesis) {{\n",
    "    var synth = window.speechSynthesis;\n",
    "    synth.speak(new window.SpeechSynthesisUtterance('{text}'));\n",
    "    }}'''.format(text=text)))\n",
    "#     clear_output(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e9b3ced",
   "metadata": {},
   "outputs": [],
   "source": [
    "video = cv2.VideoCapture(0)\n",
    "\n",
    "prev_frame = None\n",
    "ssim = 0.0\n",
    "count=0\n",
    "image_array = []\n",
    "\n",
    "display_handle=display(None, display_id=True)\n",
    "sentinel = True\n",
    "save_dir = \"\"\n",
    "good_dir = \"./good/\"\n",
    "bad_dir = \"./bad/\"\n",
    "frames_to_hold = 20\n",
    "\n",
    "while sentinel:\n",
    "    image_array = []\n",
    "    squat_type = input(\"choose (g)ood, (b)ad, (q)uit.\")\n",
    "    \n",
    "    \n",
    "    if squat_type == \"q\":\n",
    "        break\n",
    "    elif squat_type == \"g\":\n",
    "        save_dir = good_dir\n",
    "    elif squat_type == \"b\":\n",
    "        save_dir = bad_dir\n",
    "    else:\n",
    "        print(\"bad choice.\")\n",
    "        continue\n",
    "    batch_size = int(input(\"choose batch size: \"))\n",
    "    try:\n",
    "        while batch_size > 0:\n",
    "            \n",
    "\n",
    "            _, frame = video.read()\n",
    "\n",
    "            try:\n",
    "                ssim = metrics.structural_similarity(prev_frame,frame,multichannel=True)\n",
    "            except:\n",
    "                pass\n",
    "            if ssim > 0.9:\n",
    "                count += 1\n",
    "            if count > frames_to_hold:\n",
    "                if use_speech:\n",
    "                    speak(display_handle,\"ok\")\n",
    "                image_array.append(frame)\n",
    "                batch_size -= 1\n",
    "                count = 0\n",
    "            prev_frame = frame\n",
    "            display_handle.update(Image(data=cv2.imencode('.jpeg', frame)[1]))\n",
    "\n",
    "    except KeyboardInterrupt:\n",
    "        pass\n",
    "    finally:\n",
    "        video.release()\n",
    "        display_handle.update(None)\n",
    "    now = datetime.now()\n",
    "    now = now.strftime(\"%Y%m%d%H%M%S\")\n",
    "    for i in range(len(image_array)):\n",
    "        cv2.imwrite(save_dir + \"img%ddate%s.jpg\"%(i,now),image_array[i])\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2715f3e1",
   "metadata": {},
   "source": [
    "#### Sources:\n",
    "- https://stackoverflow.com/questions/27882255/is-it-possible-to-display-an-opencv-video-inside-the-ipython-jupyter-notebook\n",
    "- https://stackoverflow.com/questions/58861577/differences-between-pil-image-open-and-cv2-imdecode\n",
    "- https://www.geeksforgeeks.org/python-opencv-cv2-imread-method/\n",
    "- https://stackoverflow.com/questions/44328645/interpreting-cv2-imencode-result\n",
    "- https://docs.opencv.org/3.4/d8/d6a/group__imgcodecs__flags.html\n",
    "- https://stackoverflow.com/questions/19098104/python-opencv2-cv2-wrapper-to-get-image-size\n",
    "- https://mindtrove.info/jupyter-tidbit-run-and-say-done"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
